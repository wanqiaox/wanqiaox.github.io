---
layout: archive
title: ""
permalink: /publications/
author_profile: true
---

Reinforcement Learning
======
<a href="https://arxiv.org/abs/2506.10341" style="text-decoration: none;">Provably Learning from Language Feedback</a>, 2025 <b style='color:red;'>(Best paper in EXAIT@ICML 2025)</b>.<br />
Wanqiao Xu, Allen Nie, Ruijie Zheng, Aditya Modi, Adith Swaminathan, and Ching-An Cheng.<br />

<a href="https://arxiv.org/abs/2407.12178" style="text-decoration: none;">Exploration Unbound</a>, 2024.<br />
Dilip Arumugam\*, Wanqiao Xu\*, and Benjamin Van Roy.<br />

<a href="https://arxiv.org/abs/2312.03814" style="text-decoration: none;">Pearl: A Production-ready Reinforcement Learning Agent</a>, **Journal of Machine Learning Research**, 2024.<br />
Zheqing Zhu, Rodrigo de Salvo Braz, Jalaj Bhandari, Janiel Jiang, Yi Wan, Yonathan Efroni, Liyuan Wang, Ruiyang Xu, Hongbo Guo, Alex Nikulkov, Dmytro Korenkevych, Urun Dogan, Frank Cheng, Zheng Wu, and Wanqiao Xu.<br />

<a href="https://arxiv.org/abs/2312.01057" style="text-decoration: none;">RLHF and IIA: Perverse Incentives</a>, 2023 <b style='color:orange;'>(Oral in Models of Human Feedback for AI Alignment@ICML 2024)</b>.<br />
Wanqiao Xu, Shi Dong, Xiuyuan Lu, Grace Lam, Zheng Wen, and Benjamin Van Roy.<br />

<a href="https://arxiv.org/abs/2305.11455" style="text-decoration: none;">Shattering the Agent-Environment Interface for Fine-Tuning Inclusive Language Models</a>, 2023.<br />
Wanqiao Xu, Shi Dong, Dilip Arumugam, and Benjamin Van Roy.<br />

<a href="https://arxiv.org/abs/2211.15931" style="text-decoration: none;">Posterior Sampling for Continuing Environments</a>, **RLC 2024** <b style='color:red;'>(Outstanding paper on the theory of RL)</b>.<br />
Wanqiao Xu, Shi Dong, and Benjamin Van Roy.<br />

<a href="https://arxiv.org/abs/2110.13060" style="text-decoration: none;">Uniformly Conservative Exploration in Reinforcement Learning</a>, **AISTATS 2023**.<br />
Wanqiao Xu, Yecheng Jason Ma, Kan Xu, Hamsa Bastani, and Osbert Bastani.<br />

<a href="https://arxiv.org/abs/2210.05650" style="text-decoration: none;">Regret Bounds for Risk-Sensitive Reinforcement Learning</a>, **NeurIPS 2022**.<br />
\*Osbert Bastani, Yecheng Jason Ma, Estelle Shen, and Wanqiao Xu.<br />

Previous Publications in Probability and Number Theory
======
<a href="https://arxiv.org/abs/2102.05839" style="text-decoration: none;">Distribution of Eigenvalues of Matrix Ensembles arising from Wigner and Palindromic Toeplitz Blocks</a>, 2021.<br />
\*Keller Blackwell, Neelima Borade, Arup Bose, Charles Devlin VI, Noah Luntzlara, Renyuan Ma, Steven J. Miller, Soumendu Sundar Mukherjee, Mengxi Wang, and Wanqiao Xu.<br />
Major Revision, **Random Matrices: Theory and Applications**

<a href="https://arxiv.org/abs/1909.01935" style="text-decoration: none;">Gaps of Summands of the Zeckendorf Lattice</a>, **The Fibonacci Quarterly**, 2020, Vol. 58 Is. 2.<br />
\*Neelima Borade, Dexter Cai, David Z. Chang, Bruce Fang, Alex Liang, Steven J. Miller, and Wanqiao Xu.<br />

<a href="https://arxiv.org/abs/1908.03834" style="text-decoration: none;">Distribution of Eigenvalues of Random Real Symmetric Block Matrices</a>, 2019.<br />
\*Keller Blackwell, Neelima Borade, Charles Devlin VI, Noah Luntzlara, Renyuan Ma, Steven J. Miller, Mengxi Wang, and Wanqiao Xu.<br />

\**Author names in alphabetical order*
